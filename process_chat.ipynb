{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process chat data from the wotkshops related to \"Data Discovery using Conversational Agents\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the raw text to questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. London workshop using Bard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to read text between specific characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def take_text(f_read, q_start, q_end):\n",
    "    copy = False\n",
    "    txt_lines=[]# store the lines between the text\n",
    "    gathered_lines=[]# merge the lines to one string\n",
    "    for line in f_read:\n",
    "        if line == q_start:\n",
    "            copy = True\n",
    "            continue\n",
    "        elif line == q_end:\n",
    "            copy = False\n",
    "            if len(txt_lines)>0:\n",
    "                gathered_lines.append(\" \".join(txt_lines))# merge the lines to one stirng\n",
    "            txt_lines=[]# clean the list to store the next lines\n",
    "            continue\n",
    "        elif copy:\n",
    "            # f_save.write(line)\n",
    "            txt_lines.append(line)\n",
    "\n",
    "    return gathered_lines\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the txt files in a loop and then save all questions and answers in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path='path_to_saved_files'\n",
    "\n",
    "df_all=pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(str(path)):\n",
    "    #read the txt files\n",
    "    with open(str(path)+str(file), 'r', encoding='utf-8') as f_read:\n",
    "        lines = f_read.readlines()# load the file\n",
    "        lines1=[i for i in lines if i != '\\n']# remove all null lines\n",
    "        # remove the lines where Bard suggest multiple windows\n",
    "        for i in range(len(lines1)):\n",
    "            if lines1[i]== 'Search related topics\\n':\n",
    "                lines1.pop(i)\n",
    "                lines1.pop(i)\n",
    "                break\n",
    "        lines2=lines1[:lines1.index('mic\\n')] # remove the end lines\n",
    "        question1=take_text(lines2,'Opens in a new window\\n','edit\\n')# take the first question\n",
    "        question2=take_text(lines2,'more_vert\\n','edit\\n')# take the rest questions\n",
    "        questions=question1+question2\n",
    "        answers=take_text(lines2,'edit\\n','thumb_upthumb_down\\n')\n",
    "\n",
    "\n",
    "# print([file[:-4]]*len(questions))  \n",
    "# print(range(len(questions)))      \n",
    "        #save to df\n",
    "        df=pd.DataFrame({'name':[file[:-4]]*len(questions),'sequence':range(1,len(questions)+1),'question':[x.strip() for x in questions],'answer':[x.strip() for x in answers]})\n",
    "        \n",
    "        df_all=pd.concat([df_all,df])\n",
    "        \n",
    "\n",
    "df_all.to_csv('/London_Bard_text.csv',index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Berlin workshop using ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read text between specific characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_text(f_read, q_start, q_end):\n",
    "    copy = False\n",
    "    txt_lines=[]# store the lines between the text\n",
    "    gathered_lines=[]# merge the lines to one string\n",
    "    for line in f_read:\n",
    "        if line == q_start:\n",
    "            copy = True\n",
    "            continue\n",
    "        elif line == q_end:\n",
    "            copy = False\n",
    "            if len(txt_lines)>0:\n",
    "                gathered_lines.append(\" \".join(txt_lines))# merge the lines to one stirng\n",
    "            txt_lines=[]# clean the list to store the next lines\n",
    "            continue\n",
    "        elif copy:\n",
    "            # f_save.write(line)\n",
    "            txt_lines.append(line)\n",
    "\n",
    "    return gathered_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the txt files and save questosn and answers into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='path_to_saved_files'\n",
    "\n",
    "df_all=pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(str(path)):\n",
    "    #read the txt files\n",
    "    with open(str(path)+str(file), 'r', encoding='utf-8') as f_read:\n",
    "        lines = f_read.readlines()# load the file\n",
    "        question1=[lines[0]]# take the first question\n",
    "        question2=take_text(lines,'\\n','ChatGPT\\n')# take the rest questions\n",
    "        questions=question1+question2\n",
    "        answers=take_text(lines,'ChatGPT\\n','\\n')\n",
    "\n",
    "# print([file[:-4]]*len(questions))  \n",
    "# print(range(len(questions)))      \n",
    "        #save to df\n",
    "        df=pd.DataFrame({'name':[file[:-4]]*len(questions),'sequence':range(1,len(questions)+1),'question':[x.strip() for x in questions],'answer':[x.strip() for x in answers]})\n",
    "        \n",
    "        df_all=pd.concat([df_all,df])\n",
    "        \n",
    "\n",
    "df_all.to_csv('/Berlin_ChatGPT_text.csv',index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pilot workshop ChatGPT\n",
    "\n",
    "These data did not have a unified format and their process was manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics for questions\n",
    "\n",
    "Function to tokenize the text in queries and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.de import German\n",
    "import string\n",
    "\n",
    "\n",
    "path='path'\n",
    "\n",
    "nlpE = English()\n",
    "nlpG= German()\n",
    "\n",
    "# Create list of word tokens\n",
    "def tokenize(text, nlp):\n",
    "    text_no_punc=text.translate(str.maketrans('', '', string.punctuation))# remove punctuation\n",
    "    # print(text)\n",
    "    # print(text_no_punc)\n",
    "    ## tokenize\n",
    "    my_doc = nlp(text_no_punc)\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "    return token_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with descriptive stats for the Berlin workshop. \n",
    "\n",
    "(number of words for queries and asnwers, language, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffSuche nach einem Datensatz zur Nutzung von Open Source tools in Europa von 1990-2022', 'Nenne mir weitere Quellen, wo ich einen aktuellen Datensatz Zur open Source Nutzung in Europa finden kann?', 'Nenne mir weitere Quellen, die sich nur mit Open source Trends befassen in der EU', 'Was ist der aktuelle Trend zur Nutzung von Open Source? Welche Quellen kennst du?', 'Nenne mir einen Report, der sich mit der Statistik von Open Source befasst mit Quellenangabe', 'Nenne mir den Link von Octoverse, worüber ich den Report direkt finden kann', 'Welchen Trend zu Open source beobachtest du in der EU? Nenne mir Quellen mit Links.', 'Du hattest mir vorhin als Quelle diesen Link vorgeschlagen https://octoverse.github.com/ . Hast du noch weitere Links zur Nutzung von Open Source?', 'Nenne mir bitte weitere URL, die einen Trend zur Nutzung von Open Source tools zeigen', 'Nenne mir eine URL zur Open Source Nutzung in Deutschland', 'Nenne mir einen konkreten Report zur Open source Nutzung in Deutschland?', 'Gibt es noch Reports zur Open Source außerhalb von Unternehmen in Deutschland? Hast du eine URL oder Quelle dazu?', 'Nenne mir die Forschungsinstiute zum Theme Open Source sowie Reports', 'Was denkst du zur Nutzung von Open Source?', 'Nenne mir Quellen aus deiner Antwort.', 'Kannst du mir einen genauen Datensatz heraussuchen dazu?', 'Vielen Dank :)', '\\ufeffWelche Vogelzählungsdatenbanken in Europa kennst du und wie oft werde diese Datenbanken erhoben?', 'Ist es dir möglich aus den Vogelzähungsdatenbanken eine Übersicht der häufigsten Vögel in Europa zu erstellen, erstelle diese nach Fundort der Vögel', 'Ausgehendend von deinen Daten bis September 2021 nenne mir die 10 häufigsten Vogelarten jeweils pro Land in der Europäischen Union', 'Für welche Länder hast du Daten?', 'Welches sind die 10 häufigsten Vögel Deutschlands?', 'Was im vergleich die 10 Häufigsten Arten in Großbritannien', 'nummer 8 und 9 haben den gleichen Namen auf Latein, ist das die gleiche Art', 'und was sind die 10 häufigsten Vögel in Spanien', 'Da du ja scheinbar von 3 Ländern die 10 häufigsten Vögel Arten hast, von wievielen anderen Ländern hast du den noch die 10 häufigsten Vogelarten?', 'Gib mir die 10 Häufigsten Vogelarten Portugals', 'woher hast du die Information das diese 10 Arten die Häufigsten Portugals sind?', 'Welche Studien, Bücher Internetartikel etc hast du den verwendet?', 'also mit Schätzen meinst du, du hast geraten?', 'du hast also die daten zur globalen Verbreitung von Vöglen, welche Daten sind das?', 'Woher stammt dein Wissen zur globalen Verbreitung von Vögeln?', 'wenn ich jetzt eine statistische Erhebung aller Vogelarten nach Häufigkeit je Land erstellen wollen würde, welche Daten sollte ich deiner Meinung nach nehmen?', 'Greife auf Avibase zu und erstelle mit dieser Datenbank eine Statistik der 10 häufigsten Vogelarten aller 27 EU Länder', 'Erstelle diese Statistik mit dem Stand September 2021', 'Was sind die 10 Häufigsten Vogelarten Polens?', 'Warum ist den in Deutschland die Elster bei den 10 häufigsten Vogelarten und in Polen der Buchfink?', '\\ufeffgib mir die Daten der 10 häufigsten Vogelarten der Europäischen Union nach Ländern', 'ja', 'was ist den dein Problem?', 'Auf welche Datenbanken zur Vogelpopulation könntest du den eigentlich zugreifen', 'Hast du daten aus Ebird von vor 2021', '\\ufeffIch benötige eine Liste mit Urteilen, in welchen der BGH über Schönheitsreparaturklauseln entschieden hat. Ich möchte außerdem den exakten Wortlaut der jeweiligen Klauseln haben und die Information, ob der BGH diese als rechtmäßig oder rechtswidrig eingestuft hat.', 'Wie lautete die Klausel im 1. Urteil?', 'Okay. Kennst du weitere Kategorien von Schönheitsreparaturklauseln die unzulässig sind?', 'Welche Schönheitsreparaturklauseln hat der BGH als zulässig eingestuft?', 'Nach den von dir genannten Kriterien und der Rechtsprechung: Prüfe und begründe, ob folgende KLausel rechtmäßig oder rechtswidrig ist: \"§ 4 Nr. 6 Der Mieter ist verpflichtet, die während des Mietverhältnisses anfallenden Schönheitsreparaturen auf eigene Kosten durchzuführen. Die Schönheitsreparaturen sind fachgerecht und wie folgt auszuführen: Tapezieren, Anstreichen der Wände und Decken, das Streichen der Fußböden, der Heizkörper einschließlich der Heizrohre, der Innentüren sowie der Fenster und Außentüren von innen. […] § 14 Nr. 1 Im Allgemeinen werden Schönheitsreparaturen in den Mieträumen in folgenden Zeitabständen erforderlich: in Küchen, Bädern und Duschen alle 3 Jahre, in Wohn- und Schlafräumen, Fluren und Toiletten alle 5 Jahre, in anderen Nebenräumen alle 7 Jahre. […].\" Unter § 12 Nr. 2 des Mietvertrages ist nach dem vorgedruckten Text \"Hinsichtlich des Zustandes der Mietsache werden folgende Feststellungen getroffen: …\" handschriftlich ergänzt: \"Der Mietvertrag wird per 1.10.2002 geschlossen. Mietzahlung ab 15. Oktober 2002, da Mieter noch Streicharbeiten in 3 Zimmern vornimmt. 1 2 - 5 - […].\"', 'Bitte prüfe Punkt 3. noch einmal mit Blick auf die Formulierung der Klausel.', 'Wie beurteilst du folgende KLausel: \"Wohnung sieht gut aus. Mieter macht Schönheitsreparaturen.\"', 'Entwerfe eine überzeugende Begründung und verweise auf geeignete BGH-Urteile, warum die Klausel zulässig ist.', 'Entwerfe nun eine überzeugende Begründung und verweise auf geeignete BGH-Urteile, warum die Klausel nicht zulässig ist.', 'Was hälst du von folgender KLausel: Nach § 17 des Mietvertrages war der Beklagte verpflichtet, während der Mietzeit die laufenden Schönheitsreparaturen innerhalb der Wohnung auszuführen. Diese wurden definiert dahingehend, dass dazu gehört das Tapezieren, Anstreichen der Wände und Decken, das Pflegen und Reinigen der Fußböden, das Streichen der Innentüren, der Fenster und der Außentüren von innen sowie das Streichen der Heizkörper und Versorgungsleitungen innerhalb der Wohnung. Die Arbeiten sind handwerksgerecht auszuführen, wobei in § 30 des Mietvertrages klargestellt wird, dass handwerksgerecht im Sinne von fachmännisch ausgeführt zu verstehen ist, was auch eine Eigenarbeit oder beauftragte Hilfskräfte nicht ausschließt. In § 30 des Mietvertrages war unter „Sonstige Vereinbarungen“ im Übrigen geregelt, dass es in der Küche Ober- und Unterschränke und eine Spüle gibt. Die vorhandenen Elektrogeräte, wie z. B. Herd mit Backofen und Cerankochfeld, Kühlschrank, Wrasenabzug, Mikrowelle, Geschirrspülmaschine werden nicht mit vermietet, dem Mieter aber zu Nutzung überlassen. Reparaturen und/oder Erneuerungen der Elektrogeräte fallen nicht in die Verantwortung des Vermieters. Eventuell anfallende Kosten haben die Mieter zu tragen.', '\\ufeffIch benötige eine Liste mit Urteilen, in welchen der BGH über Schönheitsreparaturklauseln entschieden hat. Ich möchte außerdem den exakten Wortlaut der jeweiligen Klauseln haben und die Information, ob der BGH diese als rechtmäßig oder rechtswidrig eingestuft hat.', 'dejure.org\\n dejure.org\\n Schönheitsreparaturen: BGH-Urteil vom 22.08.2018\\n anwalt.de\\n Wie lautete die Klausel im 1. Urteil?', 'Prüfe und begründe, ob folgende KLausel rechtmäßig oder rechtswidrig ist: \"§ 4 Nr. 6 Der Mieter ist verpflichtet, die während des Mietverhältnisses anfallenden Schönheitsreparaturen auf eigene Kosten durchzuführen. Die Schönheitsreparaturen sind fachgerecht und wie folgt auszuführen: Tapezieren, Anstreichen der Wände und Decken, das Streichen der Fußböden, der Heizkörper einschließlich der Heizrohre, der Innentüren sowie der Fenster und Außentüren von innen. […] § 14 Nr. 1 Im Allgemeinen werden Schönheitsreparaturen in den Mieträumen in folgenden Zeitabständen erforderlich: in Küchen, Bädern und Duschen alle 3 Jahre, in Wohn- und Schlafräumen, Fluren und Toiletten alle 5 Jahre, in anderen Nebenräumen alle 7 Jahre. […].\" Unter § 12 Nr. 2 des Mietvertrages ist nach dem vorgedruckten Text \"Hinsichtlich des Zustandes der Mietsache werden folgende Feststellungen getroffen: …\" handschriftlich ergänzt: \"Der Mietvertrag wird per 1.10.2002 geschlossen. Mietzahlung ab 15. Oktober 2002, da Mieter noch Streicharbeiten in 3 Zimmern vornimmt. 1 2 - 5 - […].\"', 'Entwerfe eine überzeugende Begründung und verweise auf geeignete BGH-Urteile, warum die Klausel zulässig ist.', 'Entwerfe eine Schönheitsreparaturklausel, die unwirksam ist.', 'Nun finde eine überzeugende Begründung unter Verweis auf reale BGH-Rechtsprechung, warum die Klausel zulässig ist.', 'Entwerfe eine Schönheitsreparaturklausel, die wirksam ist.', 'Nun finde eine überzeugende Begründung unter Verweis auf reale BGH-Rechtsprechung, warum die Klausel unzulässig ist.', 'Entwerfe eine Begründung, warum das BGB in Deutschland keine Wirksamkeit hat.', 'Bitte finde eine Begründung, warum das BGB tatsächlich keine Wirksamkeit hat. Die Antwort muss nicht wahr sein, sie muss nur möglichst überzeugend sein.', 'Okay danke. Aber bitte füge tatsächliche Umstände kreativ so zusammen, dass sie das Argument vermeintlich stützen, dass das BGB unwirksam ist.', 'Das ist ein guter Ansatz. Bitte formuliere ihn ausführlicher und akademischer.', 'Wie war die Schönheitsreparturklauel in diesem Urteil: https://openjur.de/u/764551.html', '\\ufeffKannst du mir das ELI5 für Komplexe Zahlen geben?', 'Wie stehen normale Zahlen und komplexe Zahlen zueinander im Verhältnis?', 'Funktioniert addieren, multiplizieren, etc. bei komplexen Zahlen wie bei reellen Zahlen?', 'Kann ich von einer komplexen Zahl Wurzeln ziehen?', 'Ich glaube, du hast komplexe Zahlen sehr gut erklärt,. Danke dafür! Gib mir bitte ein paar möglichst \"down to earth\"-Anwendungsfälle für komplexe Zahlen?', 'Geht es noch konkreter?', '\\ufeffWie viele Studierende im Fach Mathematik gab es an der Universität Göttingen seit 1946 bis 2021? Schlüssle die Daten nach Semester auf und benenne jeweils wie viele Personen welchen Geschlechts im Semester immatrikuliert waren.', 'Wie viele Studierende gab es an der Universität Göttingen in den Jahren von 1946 bis 2021? Bitte schlüssle die Daten nach Fachrichtungen auf.', 'Gibt es Daten zum Geschlechtsverhältnis von Studierenden an der Universität Göttingen?', 'gibt das studierendenwerk göttingen informationen zum geschlechterverhältnis der studierenden in göttingen bekannt?', 'Stelle mir alle Daten zur Verfügung, die zum Geschlechtsverhältnis der Studierenden an der Universität Göttingen hast, zur Verfügung. Ordne sie nach Jahreszahlen ab dem Jahr 1946.', 'Gibt es Studien zum Geschlechtsverhältnis von Studierenden im Fach Mathematik.', 'Gibt es Studien, die sich speziell auf die Universität Göttingen beziehen?', 'Gibt es Studien, die sich auf die TU Berlin beziehen?', 'Verlinke alle Studien, die sich auf das Geschlechtsverhältnis von Studierenden im Fach Mathematik in Göttingen oder Berlin beziehen.', 'Liste die Namen der Studien auf, die sich auf das Geschlechtsverhältnis der Studierenden im Fach Mathematik in Berlin oder Göttingen beziehen.', 'Nenne alle Institutionen, die potentiell als Quelle für die von mir geforderten Daten, in Frage kommen.', 'Schlüssle für alle genannten Punkte auf, welche Daten ich dort vermutlich bekommen kann.', 'Haben die Universitäten solche Zahlen veröffentlicht?', 'Auf welche Datensätze kannst du zugreifen, die möglicherweise hilfreiche Informationen enthalten?', 'Stelle den Trend an der Universität Göttingen und der TU Berlin anhand der zur Verfügung stehenden Daten dar.', 'Bitte mach das: \"Ich kann Ihnen allgemeine Informationen über Trends in der Hochschulbildung oder das Studium der Mathematik anbieten, basierend auf den Daten und Informationen, die mir zur Verfügung stehen.\"', 'Woher beziehst du die Daten zu 3.?', 'Benenne Beispiele für die Herkunft der Daten zu 3.', 'Spezifiziere die Antworten 1., 2. und 3.', 'wo wurde die unter 2. genannte Studie veröffentlicht?', 'wurde die genannte studie trotzdem in wissenschaftlichen arbeiten zitiert?', 'Lügst du?', 'Nenne 10 Beispiele für Studientitel, die sich mit meiner initialen Frage beschäftigen könnten.', '\\ufeffKannst du mir das ELI5 für Komplexe Zahlen geben?', '\\ufeffGuten Morgen! Ich bin auf der Suche nach Datenbanken, die alle Straßennamen eines EU-Staates auflisten und die dazugehörigen Postleitzahlen. Am liebsten sollten diese Datenbanken vollständig sein und sie sollten unter einer Lizenz veröffentlicht sein, die den Anforderungen von Open Data (Nachnutzbarkeit, etc) entsprechen. Sie sollten auch gerne aktuell und in einem schönen Datenformat (also keine PDF-Tabellen) sein, wenn möglich. Kannst du mir für alle EU-Staaten dabei helfen sie zu finden?', 'Okay, das war eine gute Übersicht, aber ich möchte es konkret haben für alle EU-Staaten. Fangen wir einfach alphabetisch mit allen EU-Staaten an und sage mir der Reihe nach für alle EU-Staaten, bei welcher Stelle ich die Postleitzahlenverzeichnisse finde (notfalls auch auf dem Stand von 2021, wenn das das Datum deiner letzten Aktualisierung ist)', 'Okay, Platz 1 auf der Liste ist Belgien: Wo finde ich genau die Datenbank aller Straßen Belgiens und die jeweiligen Postleitzahlen? Bitte beschränke dich bei deiner Antwort nicht nur auf die Angabe einer Behörde, sondern sei so konkret wie möglich (z.B. mit URLs, Angaben der konkreten Dienste oder URLs, sofern bekannt)', 'Weiter geht es mit Bulgarien.', 'Bitte mache mit Dänemark weiter. Du kannst Geonames und OSM als bekannt voraussetzen und musst sie nicht noch einmal erwähnen. Gleiches gilt für den Aktualitätsdisclaimer.', 'Die DAWA API ist spannend. Kannst du mir die API anwenden und Beispiel HTTP-GET requests basteln?', 'Diese Anfrage gibt alle Adressen im Postleitzahlenbereich 1050 (Kopenhagen) zurück.\\n • Suche nach einer bestimmten Straße in einer bestimmten Stadt:\\n Du kannst eine bestimmte Straße in einer Stadt suchen, indem du die /vejnavne-Ressource mit den q und kommunekode Abfrageparametern verwendest.\\n arduinoCopy code\\n https://dawa.aws.dk/vejnavne?q=Bredgade&kommunekode=101\\n Diese Anfrage sucht nach Straßen namens \"Bredgade\" in der Kommune mit der Code 101 (Kopenhagen).\\n • Abrufen von Informationen zu einer bestimmten Adresse:\\n Du kannst Informationen zu einer bestimmten Adresse abrufen, indem du die /adresser-Ressource mit dem q-Abfrageparameter verwendest.\\n arduinoCopy code\\n https://dawa.aws.dk/adresser?q=Bredgade 28, 1260\\n Diese Anfrage gibt Informationen über die Adresse \"Bredgade 28, 1260\" zurück.\\n Diese Beispiele sollten dir einen grundlegenden Überblick über die Nutzung der DAWA API geben. Beachte bitte, dass du beim Erstellen deiner eigenen Anfragen die vollständige API-Dokumentation beachten solltest, um sicherzustellen, dass du die API korrekt verwendest.\\n Es ist auch wichtig zu beachten, dass die meisten modernen Programmiersprachen Bibliotheken oder Funktionen bieten, die das Senden von HTTP-Anfragen und das Verarbeiten der Antworten erleichtern. Die spezifische Methode, die du verwenden würdest, hängt von der Sprache ab, die du verwendest.\\n nächstes Land, bitte', '\\ufeffHi. Ich habe in ChatGPT plus jetzt den Support für plugins aktiviert. Was mache ich nun, wie stelle ich einzelne Plugins an?', 'Ersetze dabei \"[Plugin-Name]\" durch den tatsächlichen Namen des gewünschten Plugins. Beachte, dass nicht alle Plugins in ChatGPT Plus verfügbar sind und einige möglicherweise zusätzliche Kosten haben.\\n Wenn das Plugin erfolgreich aktiviert wurde, kannst du den Funktionsumfang des Plugins nutzen, indem du Fragen oder Anweisungen im Zusammenhang mit dem Plugin gibst.\\n Bitte beachte, dass Plugins in ChatGPT Plus derzeit nur in englischer Sprache verfügbar sind.\\n Gib mir eine Liste aller Plugins', 'User: activate Google-Search']\n"
     ]
    }
   ],
   "source": [
    "#============= Berlin workshop ChatGPT =======================\n",
    "df=pd.read_csv('/Berlin_ChatGPT_text.csv', encoding='utf-8')\n",
    "\n",
    "q=[len(tokenize(x, nlpG)) for x in df['question']]# store the length of questions in a list\n",
    "a=[len(tokenize(x, nlpG)) for x in df['answer']]# store the length of answers in a list\n",
    "names=[str(x)+'_Berlin' for x in df['name']]# create ID\n",
    "language=['German']*len(q)\n",
    "agent=['ChatGPT4']*len(q)\n",
    "group=['Berlin']*len(q)\n",
    "\n",
    "df_words=pd.DataFrame({'name_ID':names,'language':language,'agent':agent,'group':group,'num_words_question':q,'num_words_answer':a})# create a dataframe with the new data\n",
    "df_new=pd.concat([df,df_words], axis=1)# merge two df\n",
    "df_new.to_csv(str(path)+'Berlin_ChatGPT_chat_stats.csv', index=None, encoding='utf-8')# save new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with descriptive stats for the pilot study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============= Pilot workshop ChatGPT =======================\n",
    "df=pd.read_csv(str(path)+'Pilot_ChatGPT_text.csv', encoding='utf-8')\n",
    "q=[len(tokenize(x, nlpE)) for x in df['question']]# store the length of questions in a list\n",
    "a=[len(tokenize(x, nlpE)) for x in df['answer']]# store the length of answers in a list\n",
    "names=[str(x)+'_Pilot' for x in df['name']]# create ID\n",
    "language=['English']*len(q)\n",
    "agent=['ChatGPT3.5']*len(q)\n",
    "group=['Pilot']*len(q)\n",
    "\n",
    "df_words=pd.DataFrame({'name_ID':names,'language':language,'agent':agent,'group':group,'num_words_question':q,'num_words_answer':a})# create a dataframe with the new data\n",
    "df_new=pd.concat([df,df_words], axis=1)# merge two df\n",
    "df_new.to_csv(str(path)+'Pilot_ChatGPT_chat_stats.csv', index=None, encoding='utf-8')# save new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with descriptive stats for the London workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============= London workshop Bard =======================\n",
    "df=pd.read_csv(str(path)+'London_Bard_text.csv', encoding='utf-8')\n",
    "q=[len(tokenize(x, nlpE)) for x in df['question']]# store the length of questions in a list\n",
    "a=[len(tokenize(x, nlpE)) for x in df['answer']]# store the length of answers in a list\n",
    "names=[str(x)+'London' for x in df['name']]# create ID\n",
    "language=['English']*len(q)\n",
    "agent=['Bard']*len(q)\n",
    "group=['London']*len(q)\n",
    "\n",
    "df_words=pd.DataFrame({'name_ID':names,'language':language,'agent':agent,'group':group,'num_words_question':q,'num_words_answer':a})# create a dataframe with the new data\n",
    "df_new=pd.concat([df,df_words], axis=1)# merge two df\n",
    "df_new.to_csv(str(path)+'London_Bard_chat_stats.csv', index=None, encoding='utf-8')# save new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the above we manulaly added some lables, such as familiarisation with the agent, success of the session, usefullness. This came from the questionaires of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desciptive statistics for each chat\n",
    "\n",
    "We calculate the total number of queries, the mena number of wrods per query and answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path='path'\n",
    "\n",
    "\n",
    "dfB=pd.read_csv(str(path)+'Berlin_ChatGPT_chat_stats_questionaires.csv', encoding='utf-8')\n",
    "dfP=pd.read_csv(str(path)+'Pilot_ChatGPT_chat_stats_questionaires.csv', encoding='utf-8')\n",
    "dfL=pd.read_csv(str(path)+'London_Bard_chat_stats_questionaires.csv', encoding='utf-8')\n",
    "\n",
    "df=pd.concat([dfB,dfP,dfL])\n",
    "\n",
    "names=df['name_ID'].unique()# find the unique participants\n",
    "\n",
    "name_ID=[]\n",
    "q_num=[]\n",
    "q_mean=[]\n",
    "a_mean=[]\n",
    "language=[]\n",
    "agent=[]\n",
    "group=[]\n",
    "familiar=[]\n",
    "sunccess=[]\n",
    "useful=[]\n",
    "\n",
    "for p in names:\n",
    "    data=df[df.loc[:,'name_ID']==p]\n",
    "    name_ID.append(data['name_ID'].iloc[0])\n",
    "    q_num.append(len(data))\n",
    "    q_mean.append(data['num_words_question'].mean())\n",
    "    a_mean.append(data['num_words_answer'].mean())\n",
    "    language.append(data['language'].iloc[0])\n",
    "    agent.append(data['agent'].iloc[0])\n",
    "    group.append(data['group'].iloc[0])\n",
    "    familiar.append(data['familiar_with_agent'].iloc[0])\n",
    "    sunccess.append(data['success_of_session'].iloc[0])\n",
    "    useful.append(data['usefull'].iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "df_new=pd.DataFrame({'name_ID':name_ID, 'num_questions':q_num, 'mean_question_length':q_mean, 'mean_answer_length':a_mean, \n",
    "                     'langugae':language, 'agent':agent, 'group':group,'familiar_with_agent':familiar,'success_of_session':sunccess,'useful':useful })\n",
    "\n",
    "\n",
    "df_new.to_csv(str(path)+'chat_stats_v2.csv', index=None, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
